{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting\n",
    "\n",
    "This tutorial steps through tecnhiques to identify errors and pipeline failures, and\n",
    "avoid common pitfalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to run parallel workflows in Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Things to check first\n",
    "\n",
    "### Running in *debug* mode\n",
    "\n",
    "By default, Pydra will run with the *debug* worker, which executes each task serially\n",
    "within a single process without use of `async/await` blocks, to allow raised exceptions\n",
    "to propagate gracefully to the calling code. If you are having trouble with a pipeline,\n",
    "ensure that `worker=debug` is passed to the submission/execution call (the default).\n",
    "\n",
    "\n",
    "## Enclosing multi-process code within `if __name__ == \"__main__\"`\n",
    "\n",
    "If using the concurrent futures worker (`worker=\"cf\"`) on macOS or Windows, then you need\n",
    "to enclose top-level scripts within `if __name__ == \"__main__\"` blocks, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydra.tasks.testing import UnsafeDivisionWorkflow\n",
    "from pydra.engine.submitter import Submitter\n",
    "\n",
    "# This workflow will fail because we are trying to divide by 0\n",
    "wf = UnsafeDivisionWorkflow(a=10, b=5, denominator=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Submitter(worker=\"cf\") as sub:\n",
    "        result = sub(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Remove stray lockfiles\n",
    "\n",
    "During the execution of a task, a lockfile is generated to signify that a task is running.\n",
    "These lockfiles are released after a task completes, either successfully or with an error,\n",
    "within a *try/finally* block. However, if a task/workflow is terminated by an interactive\n",
    "debugger the finally block may not be executed causing stray lockfiles to hang around. This\n",
    "can cause the Pydra to hang waiting for the lock to be released. If you suspect this to be\n",
    "an issue, and there are no other jobs running, then simply remove all lock files from your\n",
    "cache directory (e.g. `rm <your-run-cache-dir>/*.lock`) and re-submit your job.\n",
    "\n",
    "If the  `clean_stale_locks` flag is set (by default when using the *debug* worker), locks that\n",
    "were created before the outer task was submitted are removed before the task is run.\n",
    "However, since these locks could be created by separate submission processes, ``clean_stale_locks`\n",
    "is not switched on by default when using production workers (e.g. `cf`, `slurm`, etc...).\n",
    "\n",
    "## Locating error messages\n",
    "\n",
    "If running in debug mode (the default), runtime exceptions will be raised to the\n",
    "call shell or debugger. However, when using asynchronous workers the errors will\n",
    "be saved in `_error.pklz` pickle files inside the task's cache directory. For\n",
    "example, given the following toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydra.tasks.testing import UnsafeDivisionWorkflow\n",
    "from pydra.engine.submitter import Submitter\n",
    "import nest_asyncio\n",
    "\n",
    "# This is needed to run parallel workflows in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# This workflow will fail because we are trying to divide by 0\n",
    "failing_workflow = UnsafeDivisionWorkflow(a=10, b=5).split(denominator=[3, 2 ,0])\n",
    "\n",
    "with Submitter(worker=\"cf\") as sub:\n",
    "    result = sub(failing_workflow)\n",
    "    \n",
    "if result.errored:\n",
    "    print(\"Workflow failed with errors:\\n\" + str(result.errors))\n",
    "else:\n",
    "    print(\"Workflow completed successfully :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing upstream issues\n",
    "\n",
    "Failures are common in scientific analysis, even for well tested workflows, due to\n",
    "the novel nature and of scientific experiments and known artefacts that can occur.\n",
    "Therefore, it is always to sanity-check results produced by workflows. When a problem\n",
    "occurs in a multi-stage workflow it can be difficult to identify at which stage the\n",
    "issue occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
