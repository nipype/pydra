{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "The basic runnable component of Pydra is a *task*. Tasks are conceptually similar to\n",
    "functions, in that they take inputs, operate on them and then return results. However,\n",
    "unlike functions, tasks are parameterised before they are executed in a separate step.\n",
    "This enables parameterised tasks to be linked together into workflows that are checked for\n",
    "errors before they are executed, and modular execution workers and environments to specified\n",
    "independently of the task being performed.\n",
    "\n",
    "Tasks can encapsulate Python functions, shell-commands or workflows constructed from\n",
    "task components.\n",
    "\n",
    "## Running your first task\n",
    "\n",
    "Pre-defined task definitions are installed under the `pydra.tasks.*` namespace by separate\n",
    "task packages (e.g. `pydra-fsl`, `pydra-ants`, ...). To use a pre-defined task definition\n",
    "\n",
    "* import the class from the `pydra.tasks.*` package it is in\n",
    "* instantiate it with appropriate parameters\n",
    "* \"call\" resulting object (i.e. `my_task(...)`) to execute it as you would a function \n",
    "\n",
    "To demonstrate with an example of loading a JSON file with the\n",
    "`pydra.tasks.common.LoadJson` task, we first create an example JSON file to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "import json\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow running async code in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "JSON_CONTENTS = {'a': True, 'b': 'two', 'c': 3, 'd': [7, 0.55, 6]}\n",
    "\n",
    "test_dir = Path(mkdtemp())\n",
    "json_file = test_dir / \"test.json\"\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(JSON_CONTENTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the JSON contents back from the file using the `LoadJson` task definition\n",
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.25) of nipype/pydra is available. You are using 0.25.dev128+g1e817743.d20250104\n"
     ]
    }
   ],
   "source": [
    "# Import the task definition\n",
    "from pydra.tasks.common import LoadJson\n",
    "\n",
    "# Instantiate the task definition, providing the JSON file we want to load\n",
    "load_json = LoadJson(file=json_file)\n",
    "\n",
    "# Run the task to load the JSON file\n",
    "outputs = load_json()\n",
    "\n",
    "# Access the loaded JSON output contents and check they match original\n",
    "assert outputs.out == JSON_CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access a richer `Result` object you can use a Submitter object to execute the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubmitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Submitter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Submitter() \u001b[38;5;28;01mas\u001b[39;00m submitter:\n\u001b[0;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubmitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/submitter.py:62\u001b[0m, in \u001b[0;36mSubmitter.__call__\u001b[0;34m(self, runnable, cache_locations, rerun, environment)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(runnable, TaskDef):\n\u001b[1;32m     58\u001b[0m     runnable \u001b[38;5;241m=\u001b[39m runnable\u001b[38;5;241m.\u001b[39mTask(\n\u001b[1;32m     59\u001b[0m         runnable,\n\u001b[1;32m     60\u001b[0m         cache_locations\u001b[38;5;241m=\u001b[39mcache_locations,\n\u001b[1;32m     61\u001b[0m     )\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_from_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m PersistentCache()\u001b[38;5;241m.\u001b[39mclean_up()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/envs/wf12/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/tasks.py:316\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    314\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/submitter.py:98\u001b[0m, in \u001b[0;36mSubmitter.submit_from_call\u001b[0;34m(self, runnable, rerun, environment)\u001b[0m\n\u001b[1;32m     95\u001b[0m     runnable\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# 2\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_runnable(runnable, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rerun\u001b[38;5;241m=\u001b[39mrerun)  \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/submitter.py:143\u001b[0m, in \u001b[0;36mSubmitter.expand_runnable\u001b[0;34m(self, runnable, wait, rerun)\u001b[0m\n\u001b[1;32m    138\u001b[0m     futures\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39mrun_el((task_pkl, runnable), rerun\u001b[38;5;241m=\u001b[39mrerun))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait \u001b[38;5;129;01mand\u001b[39;00m futures:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# if wait is True, we are at the end of the graph / state expansion.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Once the remaining jobs end, we will exit `submit_from_call`\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mfutures)\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# pass along futures to be awaited independently\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/workers.py:185\u001b[0m, in \u001b[0;36mConcurrentFuturesWorker.exec_as_coro\u001b[0;34m(self, runnable, rerun, environment)\u001b[0m\n\u001b[1;32m    181\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool, runnable\u001b[38;5;241m.\u001b[39m_run, rerun, environment\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# it could be tuple that includes pickle files with tasks and inputs\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     ind, task_main_pkl, task_orig \u001b[38;5;241m=\u001b[39m runnable\n\u001b[1;32m    186\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool, load_and_run, task_main_pkl, ind, rerun, environment\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from pydra.engine.submitter import Submitter\n",
    "\n",
    "with Submitter() as submitter:\n",
    "    result = submitter(load_json)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Result` object contains\n",
    "\n",
    "* `output`: the outputs of the task (if there is only one output it is called `out` by default)\n",
    "* `runtime`: information about the peak memory and CPU usage\n",
    "* `errored`: the error status of the task\n",
    "* `task`: the task object that generated the results\n",
    "* `output_dir`: the output directory the results are stored in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over inputs\n",
    "\n",
    "It is straightforward to apply the same operation over a set of inputs using the `split()`\n",
    "method. For example, if we wanted to re-grid all the NIfTI images stored in a directory,\n",
    "such as the sample ones generated by the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/var/folders/mz/yn83q2fd3s758w1j75d2nnw80000gn/T/tmpnaqc3ee3/nifti'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfileformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmedimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nifti\n\u001b[1;32m      3\u001b[0m nifti_dir \u001b[38;5;241m=\u001b[39m test_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnifti\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnifti_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m     Nifti\u001b[38;5;241m.\u001b[39msample(nifti_dir, seed\u001b[38;5;241m=\u001b[39mi)  \u001b[38;5;66;03m# Create a dummy NIfTI file in the dest. directory\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/var/folders/mz/yn83q2fd3s758w1j75d2nnw80000gn/T/tmpnaqc3ee3/nifti'"
     ]
    }
   ],
   "source": [
    "from fileformats.medimage import Nifti\n",
    "\n",
    "nifti_dir = test_dir / \"nifti\"\n",
    "nifti_dir.mkdir()\n",
    "\n",
    "for i in range(10):\n",
    "    Nifti.sample(nifti_dir, seed=i)  # Create a dummy NIfTI file in the dest. directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can by importing the `MrGrid` shell-command task from the `pydra-mrtrix3` package\n",
    "and run it over every NIfTI file in the directory using the `TaskDef.split()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MrGrid' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrtrix3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3_0\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MrGrid\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m mrgrid \u001b[38;5;241m=\u001b[39m \u001b[43mMrGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mnifti_dir\u001b[38;5;241m.\u001b[39miterdir())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the task to resample all NIfTI files\u001b[39;00m\n\u001b[1;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m mrgrid()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MrGrid' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
    "\n",
    "# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\n",
    "# by splitting the \"input\" input field over all files in the directory\n",
    "mrgrid = MrGrid(voxel=(0.5,0.5,0.5)).split(input=nifti_dir.iterdir())\n",
    "\n",
    "# Run the task to resample all NIfTI files\n",
    "outputs = mrgrid()\n",
    "\n",
    "# Print the locations of the output files\n",
    "print(\"\\n\".join(str(p) for p in outputs.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to iterate over inputs in pairs/n-tuples. For example, if you wanted to use\n",
    "different voxel sizes for different images, both the list of images and the voxel sizes\n",
    "are passed to the `split()` method and their combination is specified by a tuple \"splitter\"\n",
    "\n",
    "\n",
    "Note that it is important to use a tuple not a list for the splitter definition in this\n",
    "case, because a list splitter is interpreted as the split over each combination of inputs\n",
    "(see [Splitting and combining](../explanation/splitting-combining.html) for more details\n",
    "on splitters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mrgrid_varying_vox_sizes = MrGrid().split(\n",
    "    (\"input\", \"voxel\"),\n",
    "    input=nifti_dir.iterdir(),\n",
    "    # Define a list of voxel sizes to resample the NIfTI files to,\n",
    "    # the list must be the same length as the list of NIfTI files\n",
    "    voxel=[\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.75, 0.75, 0.75),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.25, 1.25, 1.25),\n",
    "        (1.25, 1.25, 1.25),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(mrgrid_varying_vox_sizes().output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging failed tasks\n",
    "\n",
    "Work in progress..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
