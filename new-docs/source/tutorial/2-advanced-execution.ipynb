{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Execution options\n",
                "\n",
                "One of the key design features of Pydra is the separation between the parameterisation of\n",
                "the task to be executed, and the parameresiation of where and how the task should be\n",
                "executed (e.g. on the cloud, on a HPC cluster, ...). This tutorial steps you through\n",
                "some of the available options for executing a task.\n",
                "\n",
                "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nipype/pydra-tutorial/develop/notebooks/tutorial/advanced_execution.ipynb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nest_asyncio\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Workers\n",
                "\n",
                "Pydra supports several workers with which to execute tasks\n",
                "\n",
                "- `debug` (default)\n",
                "- `cf`\n",
                "- `slurm`\n",
                "- `sge`\n",
                "- `psij`\n",
                "- `dask` (experimental)\n",
                "\n",
                "By default, the *debug* worker is used, which runs tasks serially in a single process\n",
                "without use of the `asyncio` module. This makes it easier to debug errors in workflows\n",
                "and python tasks, however, when using in Pydra in production you will typically want to\n",
                "parallelise the execution for efficiency.\n",
                "\n",
                "If running on a local workstation, then the `cf` (*ConcurrentFutures*) worker is a good\n",
                "option because it is able to spread the tasks to be run over multiple processes and\n",
                "maximise CPU usage.\n",
                "\n",
                "If you have access to a high-performance cluster (HPC) then\n",
                "the [SLURM](https://slurm.schedmd.com/documentation.html) and\n",
                "[SGE](https://www.metagenomics.wiki/tools/hpc-sge) and [PSI/J](https://exaworks.org/psij)\n",
                "workers can be used to submit each workflow node as separate jobs to the HPC scheduler.\n",
                "There is also an experimental [Dask](https://www.dask.org/) worker, which provides a\n",
                "range of execution backends to choose from.\n",
                "\n",
                "To specify a worker, the abbreviation can be passed either as a string or using the\n",
                "class itself. Additional parameters can be passed to the worker initialisation as keyword\n",
                "arguments to the execution call. For example, if we wanted to run five tasks using the\n",
                "ConcurentFutures worker but only use three CPUs, we can pass `n_procs=3` to the execution\n",
                "call."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "A newer version (0.25) of nipype/pydra is available. You are using 0.25.dev144+g6a590e9d.d20250124\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "Graph of 'Workflow(name='Split', inputs=Split(_constructed=None, defn=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), constructor=<function Submitter.__call__.<locals>.Split at 0x114510d60>), outputs=SplitOutputs(out=LazyOutField(field='out', type=list[int], cast_from=None, type_checked=True, node=Node(name='TenToThePower', _definition=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), _workflow=..., _lzout=TenToThePowerOutputs(out=...), _state=<pydra.engine.state.State object at 0x114609130>, _cont_dim=None, _inner_cont_dim={}))), _nodes={'TenToThePower': Node(name='TenToThePower', _definition=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), _workflow=..., _lzout=TenToThePowerOutputs(out=LazyOutField(field='out', type=list[int], cast_from=None, type_checked=True, node=...)), _state=<pydra.engine.state.State object at 0x114609130>, _cont_dim=None, _inner_cont_dim={})})' workflow is not empty, but not able to get more tasks - something has gone wrong when retrieving the results predecessors:\n\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m ten_to_the_power \u001b[38;5;241m=\u001b[39m TenToThePower()\u001b[38;5;241m.\u001b[39msplit(p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run the 5 tasks in parallel split across 3 processes\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mten_to_the_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_procs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m p1, p2, p3, p4, p5 \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mout\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10^5 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp5\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/specs.py:194\u001b[0m, in \u001b[0;36mTaskDef.__call__\u001b[0;34m(self, cache_dir, worker, environment, rerun, cache_locations, audit_flags, messengers, messenger_args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Submitter(\n\u001b[1;32m    184\u001b[0m         audit_flags\u001b[38;5;241m=\u001b[39maudit_flags,\n\u001b[1;32m    185\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    193\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m sub:\n\u001b[0;32m--> 194\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__notes__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m WORKER_KWARG_FAIL_NOTE \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__notes__:\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/submitter.py:156\u001b[0m, in \u001b[0;36mSubmitter.__call__\u001b[0;34m(self, task_def)\u001b[0m\n\u001b[1;32m    154\u001b[0m task \u001b[38;5;241m=\u001b[39m Task(task_def, submitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m, environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mis_async:  \u001b[38;5;66;03m# Only workflow tasks can be async\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39mrun(task, rerun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrerun)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.5/envs/wf12/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/workers.py:51\u001b[0m, in \u001b[0;36mWorker.run_async\u001b[0;34m(self, task, rerun)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask[DefType]\u001b[39m\u001b[38;5;124m\"\u001b[39m, rerun: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mrun_async(rerun\u001b[38;5;241m=\u001b[39mrerun)\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/core.py:416\u001b[0m, in \u001b[0;36mTask.run_async\u001b[0;34m(self, rerun)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudit\u001b[38;5;241m.\u001b[39mmonitor()\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefinition\u001b[38;5;241m.\u001b[39m_run_async(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    417\u001b[0m     result\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefinition\u001b[38;5;241m.\u001b[39mOutputs\u001b[38;5;241m.\u001b[39m_from_task(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/specs.py:709\u001b[0m, in \u001b[0;36mWorkflowDef._run_async\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask[WorkflowDef]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the workflow asynchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39msubmitter\u001b[38;5;241m.\u001b[39mexpand_workflow_async(task)\n",
                        "File \u001b[0;32m~/git/workflows/pydra/pydra/engine/submitter.py:285\u001b[0m, in \u001b[0;36mSubmitter.expand_workflow_async\u001b[0;34m(self, workflow_task)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m hashes_have_changed:\n\u001b[1;32m    273\u001b[0m                 msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    274\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet loglevel to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in order to track hash changes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthroughout the execution of the workflow.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor more types in your interface inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m                 )\n\u001b[0;32m--> 285\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mis_async:\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Graph of 'Workflow(name='Split', inputs=Split(_constructed=None, defn=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), constructor=<function Submitter.__call__.<locals>.Split at 0x114510d60>), outputs=SplitOutputs(out=LazyOutField(field='out', type=list[int], cast_from=None, type_checked=True, node=Node(name='TenToThePower', _definition=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), _workflow=..., _lzout=TenToThePowerOutputs(out=...), _state=<pydra.engine.state.State object at 0x114609130>, _cont_dim=None, _inner_cont_dim={}))), _nodes={'TenToThePower': Node(name='TenToThePower', _definition=TenToThePower(p=StateArray(1, 2, 3, 4, 5), function=<function TenToThePower at 0x10b6f3420>), _workflow=..., _lzout=TenToThePowerOutputs(out=LazyOutField(field='out', type=list[int], cast_from=None, type_checked=True, node=...)), _state=<pydra.engine.state.State object at 0x114609130>, _cont_dim=None, _inner_cont_dim={})})' workflow is not empty, but not able to get more tasks - something has gone wrong when retrieving the results predecessors:\n\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "from pydra.design import python\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "\n",
                "    @python.define\n",
                "    def TenToThePower(p: int) -> int:\n",
                "        return 10 ** p\n",
                "\n",
                "    ten_to_the_power = TenToThePower().split(p=[1, 2, 3, 4, 5])\n",
                "\n",
                "    # Run the 5 tasks in parallel split across 3 processes\n",
                "    outputs = ten_to_the_power(worker=\"cf\", n_procs=3)\n",
                "\n",
                "    p1, p2, p3, p4, p5 = outputs.out\n",
                "\n",
                "    print(f\"10^5 = {p5}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Alternatively, the worker object can be initialised in the calling code and passed directly to the execution call"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydra.engine.workers import ConcurrentFuturesWorker\n",
                "\n",
                "ten_to_the_power = TenToThePower().split(p=[6, 7, 8, 9, 10])\n",
                "\n",
                "# Run the 5 tasks in parallel split across 3 processes\n",
                "outputs = ten_to_the_power(worker=ConcurrentFuturesWorker(n_procs=3))\n",
                "\n",
                "p6, p7, p8, p9, p10 = outputs.out\n",
                "\n",
                "print(f\"10^10 = {p10}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cache locations\n",
                "\n",
                "When a task runs, a unique hash is generated by the combination of all the inputs to the\n",
                "task and the operation to be performed. This hash is used to name the output directory for\n",
                "the task within the specified cache directory. Therefore, if you use the same cache\n",
                "directory between runs and in a subsequent run the same task is executed with the same\n",
                "inputs then the location of its output directory will also be the same, and the outputs\n",
                "generated by the previous run are reused.\n",
                "\n",
                "For example, using the MrGrid example from the [Getting Started Tutorial](./1-getting-started.html)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import tempfile\n",
                "from fileformats.medimage import Nifti1\n",
                "from pydra.engine.submitter import Submitter\n",
                "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
                "\n",
                "# Make directory filled with nifti files\n",
                "test_dir = Path(tempfile.mkdtemp())\n",
                "nifti_dir = test_dir / \"nifti\"\n",
                "nifti_dir.mkdir()\n",
                "for i in range(10):\n",
                "    Nifti1.sample(nifti_dir, seed=i)\n",
                "\n",
                "# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\n",
                "# by splitting the \"input\" input field over all files in the directory\n",
                "mrgrid = MrGrid(operation=\"regrid\", voxel=(0.5, 0.5, 0.5)).split(\n",
                "    in_file=nifti_dir.iterdir()\n",
                ")\n",
                "\n",
                "# Run the task to resample all NIfTI files\n",
                "outputs = mrgrid()\n",
                "\n",
                "# Create a new custom directory\n",
                "cache_dir = test_dir / \"cache\"\n",
                "cache_dir.mkdir()\n",
                "\n",
                "submitter = Submitter(cache_dir=cache_dir)\n",
                "\n",
                "# Run the task to resample all NIfTI files with different voxel sizes\n",
                "with submitter:\n",
                "    result1 = submitter(mrgrid)\n",
                "\n",
                "print(result1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we attempt to run the same task with the same parameterisation the cache directory\n",
                "will point to the same location and the results will be reused"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mrgrid_varying_vox_sizes2 = MrGrid().split(\n",
                "    (\"input\", \"voxel\"),\n",
                "    input=nifti_dir.iterdir(),\n",
                "    voxel=VOXEL_SIZES\n",
                ")\n",
                "\n",
                "submitter = Submitter(cache_dir=test_dir / \"cache\")\n",
                "\n",
                "# Result from previous run is reused as the task and inputs are identical\n",
                "with submitter:\n",
                "    result2 = submitter(mrgrid_varying_vox_sizes2)\n",
                "\n",
                "\n",
                "# Check that the output directory is the same for both runs\n",
                "assert result2.output_dir == result1.output_dir\n",
                "\n",
                "# Change the voxel sizes to resample the NIfTI files to for one of the files\n",
                "mrgrid_varying_vox_sizes2.inputs.voxel[2] = [0.25]\n",
                "\n",
                "# Result from previous run is reused as the task and inputs are identical\n",
                "with submitter:\n",
                "    result3 = submitter(mrgrid_varying_vox_sizes2)\n",
                "\n",
                "# The output directory will be different as the inputs are now different\n",
                "assert result3.output_dir != result1.output_dir"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that for file objects, the contents of the files are used to calculate the hash\n",
                "not their paths. Therefore, when inputting large files there might be some additional\n",
                "overhead on the first run (the file hashes themselves are cached by path and mtime so\n",
                "shouldn't need to be recalculated unless they are modified). However, this makes the\n",
                "hashes invariant to file-system movement. For example, changing the name of one of the\n",
                "files in the nifti directory won't invalidate the hash."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rename a NIfTI file within the test directory\n",
                "first_file = next(nifti_dir.iterdir())\n",
                "first_file.rename(first_file.with_name(\"first.nii.gz\"))\n",
                "\n",
                "mrgrid_varying_vox_sizes3 = MrGrid().split(\n",
                "    (\"input\", \"voxel\"),\n",
                "    input=nifti_dir.iterdir(),\n",
                "    voxel=VOXEL_SIZES\n",
                ")\n",
                "\n",
                "# Result from previous run is reused as the task and inputs are identical\n",
                "with submitter:\n",
                "    result4 = submitter(mrgrid_varying_vox_sizes2)\n",
                "\n",
                "# Check that the output directory is the same for both runs\n",
                "assert result4.output_dir == result1.output_dir"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "See [Caches and hashes](../explanation/hashing-caching.html) for more details on how inputs\n",
                "are hashed for caching and issues to consider."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Environments\n",
                "\n",
                "Work in progress...\n",
                "\n",
                "See [Containers and Environments](../explanation/environments.rst) for more details."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Provenance and auditing\n",
                "\n",
                "Work in progress..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "wf12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
