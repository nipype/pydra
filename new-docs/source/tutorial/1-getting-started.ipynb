{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "The basic runnable component of Pydra is a *task*. Tasks are conceptually similar to\n",
    "functions, in that they take inputs, operate on them and then return results. However,\n",
    "unlike functions, tasks are parameterised before they are executed in a separate step.\n",
    "This enables parameterised tasks to be linked together into workflows that are checked for\n",
    "errors before they are executed, and modular execution workers and environments to specified\n",
    "independently of the task being performed.\n",
    "\n",
    "Tasks can encapsulate Python functions, shell-commands or workflows constructed from\n",
    "task components.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before we get started, lets set up some test data to play with.\n",
    "\n",
    "Here we create a sample JSON file in a temporary directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "import json\n",
    "\n",
    "JSON_CONTENTS = {'a': True, 'b': 'two', 'c': 3, 'd': [7, 0.55, 6]}\n",
    "\n",
    "test_dir = Path(mkdtemp())\n",
    "json_file = test_dir / \"test.json\"\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(JSON_CONTENTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a directory containing ten randomly generated [NIfTI](https://nifti.nimh.nih.gov/) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileformats.medimage import Nifti1\n",
    "\n",
    "nifti_dir = test_dir / \"nifti\"\n",
    "nifti_dir.mkdir()\n",
    "\n",
    "for i in range(10):\n",
    "    Nifti1.sample(nifti_dir, seed=i)  # Create a dummy NIfTI file in the dest. directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you run concurrent processes within a Jupyter notebook the following snippet\n",
    "is also required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Running your first task\n",
    "\n",
    "Pre-defined task definitions are installed under the `pydra.tasks.*` namespace by separate\n",
    "task packages (e.g. `pydra-fsl`, `pydra-ants`, ...). To use a pre-defined task definition\n",
    "\n",
    "* import the class from the `pydra.tasks.*` package it is in\n",
    "* instantiate it with appropriate parameters\n",
    "* \"call\" resulting object (i.e. `my_task(...)`) to execute it as you would a function \n",
    "\n",
    "To demonstrate with an example of loading a JSON file with the\n",
    "`pydra.tasks.common.LoadJson` task, we first create an example JSON file to test with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the JSON contents back from the file using the `LoadJson` task definition\n",
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.25) of nipype/pydra is available. You are using 0.25.dev141+g03c7438b.d20250123\n"
     ]
    }
   ],
   "source": [
    "# Import the task definition\n",
    "from pydra.tasks.common import LoadJson\n",
    "\n",
    "# Instantiate the task definition, providing the JSON file we want to load\n",
    "load_json = LoadJson(file=json_file)\n",
    "\n",
    "# Run the task to load the JSON file\n",
    "outputs = load_json()\n",
    "\n",
    "# Access the loaded JSON output contents and check they match original\n",
    "assert outputs.out == JSON_CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access a richer `Result` object you can use a Submitter object to execute the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(task=<pydra.engine.core.Task object at 0x10dc42fc0>, outputs=LoadJsonOutputs(out={'a': True, 'b': 'two', 'c': 3, 'd': [7, 0.55, 6]}), runtime=None, errored=False)\n"
     ]
    }
   ],
   "source": [
    "from pydra.engine.submitter import Submitter\n",
    "\n",
    "with Submitter() as submitter:\n",
    "    result = submitter(load_json)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Result` object contains\n",
    "\n",
    "* `output`: the outputs of the task (if there is only one output it is called `out` by default)\n",
    "* `runtime`: information about the peak memory and CPU usage\n",
    "* `errored`: the error status of the task\n",
    "* `task`: the task object that generated the results\n",
    "* `output_dir`: the output directory the results are stored in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over inputs\n",
    "\n",
    "It is straightforward to apply the same operation over a set of inputs using the `split()`\n",
    "method. For example, if we wanted to re-grid all the NIfTI images stored in a directory,\n",
    "such as the sample ones generated by the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can by importing the `MrGrid` shell-command task from the `pydra-mrtrix3` package\n",
    "and run it over every NIfTI file in the directory using the `TaskDef.split()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n"
     ]
    }
   ],
   "source": [
    "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
    "\n",
    "# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\n",
    "# by splitting the \"input\" input field over all files in the directory\n",
    "mrgrid = MrGrid(operation=\"regrid\", voxel=(0.5,0.5,0.5)).split(in_file=nifti_dir.iterdir())\n",
    "\n",
    "# Run the task to resample all NIfTI files\n",
    "outputs = mrgrid()\n",
    "\n",
    "# Print the locations of the output files\n",
    "print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to iterate over inputs in pairs/n-tuples. For example, if you wanted to use\n",
    "different voxel sizes for different images, both the list of images and the voxel sizes\n",
    "are passed to the `split()` method and their combination is specified by a tuple \"splitter\"\n",
    "\n",
    "\n",
    "Note that it is important to use a tuple not a list for the splitter definition in this\n",
    "case, because a list splitter is interpreted as the split over each combination of inputs\n",
    "(see [Splitting and combining](../explanation/splitting-combining.html) for more details\n",
    "on splitters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n",
      "/Users/tclose/Library/Caches/pydra/0.24.dev36+g0deadc43/run-cache/Task_c989fc46725c0d124dc287f463674e63/out_file.mif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mrgrid_varying_vox_sizes = MrGrid(operation=\"regrid\").split(\n",
    "    (\"in_file\", \"voxel\"),\n",
    "    in_file=nifti_dir.iterdir(),\n",
    "    # Define a list of voxel sizes to resample the NIfTI files to,\n",
    "    # the list must be the same length as the list of NIfTI files\n",
    "    voxel=[\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.75, 0.75, 0.75),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.25, 1.25, 1.25),\n",
    "        (1.25, 1.25, 1.25),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing tasks in parallel\n",
    "\n",
    "By default, Pydra will use the *debug* worker, which executes each task sequentially.\n",
    "This makes it easier to debug tasks and workflows, however, in most cases, once a workflow\n",
    "is ready to go, a concurrent worker is preferable so tasks can be executed in parallel\n",
    "(see [Workers](./2-advanced-execution.html#Workers)). To use multiple processes on a\n",
    "workstation, select the `cf` worker option when executing the task/workflow.\n",
    "\n",
    "Note that when multiprocessing in Python on Windows and macOS (and good practice on Linux/POSIX\n",
    "OSs for compatibility), you need to place a `if __name__ == \"__main__\"` block when\n",
    "executing in top-level scripts to allow the script to be imported, but not executed,\n",
    "by subprocesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nifti_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrtrix3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3_0\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MrGrid\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# <-- Add this block to allow the script to imported by subprocesses\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     mrgrid \u001b[38;5;241m=\u001b[39m MrGrid(operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregrid\u001b[39m\u001b[38;5;124m\"\u001b[39m, voxel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m))\u001b[38;5;241m.\u001b[39msplit(in_file\u001b[38;5;241m=\u001b[39m\u001b[43mnifti_dir\u001b[49m\u001b[38;5;241m.\u001b[39miterdir())\n\u001b[1;32m      5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m mrgrid(worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# <-- Select the \"cf\" worker here\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mout_file))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nifti_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
    "\n",
    "if __name__ == \"__main__\":  # <-- Add this block to allow the script to imported by subprocesses\n",
    "    mrgrid = MrGrid(operation=\"regrid\", voxel=(0.5,0.5,0.5)).split(in_file=nifti_dir.iterdir())\n",
    "    outputs = mrgrid(worker=\"cf\")  # <-- Select the \"cf\" worker here\n",
    "    print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging failed tasks\n",
    "\n",
    "Work in progress..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
