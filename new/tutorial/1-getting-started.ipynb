{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "The basic runnable component of Pydra is a *task*. Tasks are conceptually similar to\n",
    "functions, in that they take inputs, operate on them and then return results. However,\n",
    "unlike functions, tasks are parameterised before they are executed in a separate step.\n",
    "This enables parameterised tasks to be linked together into workflows that are checked for\n",
    "errors before they are executed, and modular execution workers and environments to specified\n",
    "independently of the task being performed.\n",
    "\n",
    "Tasks can encapsulate Python functions or shell-commands, or be multi-component workflows,\n",
    "themselves constructed from task components including nested workflows.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before we get started, lets set up some test data to play with. Here we create a sample\n",
    "JSON file in a temporary directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:28.667277Z",
     "iopub.status.busy": "2025-02-10T00:06:28.667108Z",
     "iopub.status.idle": "2025-02-10T00:06:28.671597Z",
     "shell.execute_reply": "2025-02-10T00:06:28.671083Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "import json\n",
    "\n",
    "JSON_CONTENTS = {'a': True, 'b': 'two', 'c': 3, 'd': [7, 0.55, 6]}\n",
    "\n",
    "test_dir = Path(mkdtemp())\n",
    "json_file = test_dir / \"test.json\"\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(JSON_CONTENTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a directory containing 10 randomly generated [NIfTI](https://nifti.nimh.nih.gov/) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:28.673441Z",
     "iopub.status.busy": "2025-02-10T00:06:28.673108Z",
     "iopub.status.idle": "2025-02-10T00:06:28.921983Z",
     "shell.execute_reply": "2025-02-10T00:06:28.921472Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m nifti_dir\u001b[38;5;241m.\u001b[39mmkdir()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mNifti1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnifti_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Create a dummy NIfTI file in the dest. directory\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.1/x64/lib/python3.13/site-packages/fileformats/core/fileset.py:1050\u001b[0m, in \u001b[0;36mFileSet.sample\u001b[0;34m(cls, dest_dir, seed, stem)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     dest_dir \u001b[38;5;241m=\u001b[39m Path(tempfile\u001b[38;5;241m.\u001b[39mmkdtemp())\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# Need to use mock to get an instance in order to use the singledispatch-based\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# extra decorator\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m fspaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSampleFileGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_stem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(fspaths)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.1/x64/lib/python3.13/site-packages/fileformats/core/fileset.py:1083\u001b[0m, in \u001b[0;36mFileSet.sample_data\u001b[0;34m(cls, generator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the `generate_sample_data` method into a class method by mocking up\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03ma class instance and calling the method on it\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    the generated file-system paths\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m mock: FileSet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmock()\n\u001b[0;32m-> 1083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.1/x64/lib/python3.13/site-packages/fileformats/core/extras.py:37\u001b[0m, in \u001b[0;36mextra.<locals>.decorated\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[1;32m     36\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreferenced_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     extras\u001b[38;5;241m.\u001b[39mappend(import_extras_module(tp))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.1/x64/lib/python3.13/site-packages/fileformats/core/fileset.py:989\u001b[0m, in \u001b[0;36mFileSet.referenced_types\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreferenced_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m types\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "from fileformats.medimage import Nifti1\n",
    "\n",
    "nifti_dir = test_dir / \"nifti\"\n",
    "nifti_dir.mkdir()\n",
    "\n",
    "for i in range(10):\n",
    "    Nifti1.sample(nifti_dir, seed=i)  # Create a dummy NIfTI file in the dest. directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you run concurrent processes within a Jupyter notebook the following snippet\n",
    "is also required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:28.923903Z",
     "iopub.status.busy": "2025-02-10T00:06:28.923589Z",
     "iopub.status.idle": "2025-02-10T00:06:28.926919Z",
     "shell.execute_reply": "2025-02-10T00:06:28.926393Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Running your first task\n",
    "\n",
    "Pre-defined task definitions are installed under the `pydra.tasks.*` namespace by separate\n",
    "task packages (e.g. `pydra-fsl`, `pydra-ants`, ...). To use a pre-defined task definition\n",
    "\n",
    "* import the class from the `pydra.tasks.*` package it is in\n",
    "* instantiate it with appropriate parameters\n",
    "* \"call\" resulting object (i.e. `my_task(...)`) to execute it as you would a function \n",
    "\n",
    "To demonstrate with an example of loading a JSON file with the\n",
    "`pydra.tasks.common.LoadJson` task, we first create an example JSON file to test with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the JSON contents back from the file using the `LoadJson` task definition\n",
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:28.928825Z",
     "iopub.status.busy": "2025-02-10T00:06:28.928418Z",
     "iopub.status.idle": "2025-02-10T00:06:30.097936Z",
     "shell.execute_reply": "2025-02-10T00:06:30.097360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.25) of nipype/pydra is available. You are using 0.25.dev193+gb1c4dc12\n"
     ]
    }
   ],
   "source": [
    "# Import the task definition\n",
    "from pydra.tasks.common import LoadJson\n",
    "\n",
    "# Instantiate the task definition, providing the JSON file we want to load\n",
    "load_json = LoadJson(file=json_file)\n",
    "\n",
    "# Run the task to load the JSON file\n",
    "outputs = load_json()\n",
    "\n",
    "# Access the loaded JSON output contents and check they match original\n",
    "assert outputs.out == JSON_CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over inputs\n",
    "\n",
    "It is straightforward to apply the same operation over a set of inputs using the `split()`\n",
    "method. For example, if we wanted to re-grid all the NIfTI images stored in a directory,\n",
    "such as the sample ones generated by the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can by importing the `MrGrid` shell-command task from the `pydra-mrtrix3` package\n",
    "and run it over every NIfTI file in the directory using the `TaskDef.split()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:30.099847Z",
     "iopub.status.busy": "2025-02-10T00:06:30.099622Z",
     "iopub.status.idle": "2025-02-10T00:06:30.124911Z",
     "shell.execute_reply": "2025-02-10T00:06:30.124471Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydra.tasks.mrtrix3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrtrix3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3_0\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MrGrid\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# by splitting the \"input\" input field over all files in the directory\u001b[39;00m\n\u001b[1;32m      5\u001b[0m mrgrid \u001b[38;5;241m=\u001b[39m MrGrid(operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregrid\u001b[39m\u001b[38;5;124m\"\u001b[39m, voxel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m))\u001b[38;5;241m.\u001b[39msplit(in_file\u001b[38;5;241m=\u001b[39mnifti_dir\u001b[38;5;241m.\u001b[39miterdir())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydra.tasks.mrtrix3'"
     ]
    }
   ],
   "source": [
    "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
    "\n",
    "# Instantiate the task definition, \"splitting\" over all NIfTI files in the test directory\n",
    "# by splitting the \"input\" input field over all files in the directory\n",
    "mrgrid = MrGrid(operation=\"regrid\", voxel=(0.5,0.5,0.5)).split(in_file=nifti_dir.iterdir())\n",
    "\n",
    "# Run the task to resample all NIfTI files\n",
    "outputs = mrgrid()\n",
    "\n",
    "# Print the locations of the output files\n",
    "print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to iterate over inputs in pairs/n-tuples. For example, if you wanted to use\n",
    "different voxel sizes for different images, both the list of images and the voxel sizes\n",
    "are passed to the `split()` method and their combination is specified by a tuple \"splitter\"\n",
    "\n",
    "\n",
    "Note that it is important to use a tuple not a list for the splitter definition in this\n",
    "case, because a list splitter is interpreted as the split over each combination of inputs\n",
    "(see [Splitting and combining](../explanation/splitting-combining.html) for more details\n",
    "on splitters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:30.127061Z",
     "iopub.status.busy": "2025-02-10T00:06:30.126546Z",
     "iopub.status.idle": "2025-02-10T00:06:30.143037Z",
     "shell.execute_reply": "2025-02-10T00:06:30.142587Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MrGrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mrgrid_varying_vox_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mMrGrid\u001b[49m(operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m      2\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoxel\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m     in_file\u001b[38;5;241m=\u001b[39mnifti_dir\u001b[38;5;241m.\u001b[39miterdir(),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Define a list of voxel sizes to resample the NIfTI files to,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# the list must be the same length as the list of NIfTI files\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     voxel\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      7\u001b[0m         (\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m      8\u001b[0m         (\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m      9\u001b[0m         (\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m     10\u001b[0m         (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     11\u001b[0m         (\u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.75\u001b[39m),\n\u001b[1;32m     12\u001b[0m         (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     13\u001b[0m         (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     14\u001b[0m         (\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m     15\u001b[0m         (\u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m1.25\u001b[39m),\n\u001b[1;32m     16\u001b[0m         (\u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m1.25\u001b[39m),\n\u001b[1;32m     17\u001b[0m     ],\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mout_file))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MrGrid' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mrgrid_varying_vox_sizes = MrGrid(operation=\"regrid\").split(\n",
    "    (\"in_file\", \"voxel\"),\n",
    "    in_file=nifti_dir.iterdir(),\n",
    "    # Define a list of voxel sizes to resample the NIfTI files to,\n",
    "    # the list must be the same length as the list of NIfTI files\n",
    "    voxel=[\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.75, 0.75, 0.75),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (1.0, 1.0, 1.0),\n",
    "        (1.25, 1.25, 1.25),\n",
    "        (1.25, 1.25, 1.25),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing tasks in parallel\n",
    "\n",
    "By default, Pydra will use the *debug* worker, which executes each task sequentially.\n",
    "This makes it easier to debug tasks and workflows, however, in most cases, once a workflow\n",
    "is tested, a concurrent worker is preferable so tasks can be executed in parallel\n",
    "(see [Workers](./3-advanced-execution.html#Workers)). To use multiple processes on a\n",
    "workstation, select the `cf` worker option when executing the task/workflow. Additional\n",
    "keyword arguments, will be passed to the worker initialisation (e.g. `n_procs=4`).\n",
    "\n",
    "Note that when multiprocessing in Python on Windows and macOS (and good practice on Linux/POSIX\n",
    "OSs for compatibility), you need to place a `if __name__ == \"__main__\"` block when\n",
    "executing in top-level scripts to allow the script to be imported, but not executed,\n",
    "by subprocesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:30.144851Z",
     "iopub.status.busy": "2025-02-10T00:06:30.144508Z",
     "iopub.status.idle": "2025-02-10T00:06:30.157212Z",
     "shell.execute_reply": "2025-02-10T00:06:30.156757Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydra.tasks.mrtrix3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrtrix3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3_0\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MrGrid\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# <-- Add this block to allow the script to imported by subprocesses\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     mrgrid \u001b[38;5;241m=\u001b[39m MrGrid(operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregrid\u001b[39m\u001b[38;5;124m\"\u001b[39m, voxel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m))\u001b[38;5;241m.\u001b[39msplit(in_file\u001b[38;5;241m=\u001b[39mnifti_dir\u001b[38;5;241m.\u001b[39miterdir())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydra.tasks.mrtrix3'"
     ]
    }
   ],
   "source": [
    "from pydra.tasks.mrtrix3.v3_0 import MrGrid\n",
    "\n",
    "if __name__ == \"__main__\":  # <-- Add this block to allow the script to imported by subprocesses\n",
    "    mrgrid = MrGrid(operation=\"regrid\", voxel=(0.5,0.5,0.5)).split(in_file=nifti_dir.iterdir())\n",
    "    outputs = mrgrid(worker=\"cf\", n_procs=4)  # <-- Select the \"cf\" worker here\n",
    "    print(\"\\n\".join(str(p) for p in outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File-system locations\n",
    "\n",
    "Output and intermediate files are typically generated during the course of a workflow/task run.\n",
    "In addition to this, Pydra generates a cache directory for each task, in which\n",
    "the task definition, results and any errors are stored in [cloudpickle](https://github.com/cloudpipe/cloudpickle)\n",
    "files for future reference (see [Troubleshooting](./troubleshooting.html)).\n",
    "By default, these cache directories are stored in a platform-specific application-cache\n",
    "directory\n",
    "\n",
    "* Windows: `C:\\Users\\<username>\\AppData\\Local\\pydra\\<pydra-version>\\run-cache`\n",
    "* Linux: `/home/<username>/.cache/pydra/<pydra-version>/run-cache`\n",
    "* macOS: `/Users/<username>/Library/Caches/pydra/<pydra-version>/run-cache`\n",
    "\n",
    "When a task runs, a unique hash is generated by the combination of all the inputs to the\n",
    "task and the operation to be performed. This hash is used to name the task cache directory\n",
    "within the specified cache root. Therefore, if you use the same cache\n",
    "root and in a subsequent run the same task is executed with the same\n",
    "inputs, then the path of its cache directory will be the same, and if Pydra finds\n",
    "existing results at that path, then the outputs generated by the previous run will be\n",
    "reused.\n",
    "\n",
    "This cache will grow as more runs are called, therefore care needs to be taken to ensure\n",
    "there is enough space on the target disk. Since the cache will be constantly To specify\n",
    "a different location for this cache, simply provide the `cache_root` keyword argument to the execution call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:30.159051Z",
     "iopub.status.busy": "2025-02-10T00:06:30.158710Z",
     "iopub.status.idle": "2025-02-10T00:06:30.170491Z",
     "shell.execute_reply": "2025-02-10T00:06:30.169947Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mrgrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmrgrid\u001b[49m(cache_root\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/pydra-cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mrgrid' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = mrgrid(cache_root=Path(\"~/pydra-cache\").expanduser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check alternative cache roots, while storing any generated task cache dirs in the \n",
    "specified cache root, the `cache_locations` keyword argument can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T00:06:30.172454Z",
     "iopub.status.busy": "2025-02-10T00:06:30.172231Z",
     "iopub.status.idle": "2025-02-10T00:06:30.184572Z",
     "shell.execute_reply": "2025-02-10T00:06:30.184100Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mrgrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m my_cache_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/pydra-cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\n\u001b[1;32m      4\u001b[0m my_cache_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmrgrid\u001b[49m(\n\u001b[1;32m      7\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mmy_cache_dir,\n\u001b[1;32m      8\u001b[0m     cache_locations\u001b[38;5;241m=\u001b[39m[default_run_cache_dir]\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mrgrid' is not defined"
     ]
    }
   ],
   "source": [
    "from pydra.utils import default_run_cache_dir\n",
    "\n",
    "my_cache_dir = Path(\"~/pydra-cache\").expanduser()\n",
    "my_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outputs = mrgrid(\n",
    "    cache_dir=my_cache_dir,\n",
    "    cache_locations=[default_run_cache_dir]\n",
    ")\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
