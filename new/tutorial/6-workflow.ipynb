{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflows\n",
    "\n",
    "In Pydra, workflows are DAG of component tasks to be executed on specified inputs.\n",
    "Workflow definitions are dataclasses, which interchangeable with Python and shell tasks\n",
    "definitions and executed in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor functions\n",
    "\n",
    "Workflows are typically defined using the `pydra.design.workflow.define` decorator on \n",
    "a \"constructor\" function that generates the workflow. For example, given two task\n",
    "definitions, `Add` and `Mul`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.342403Z",
     "iopub.status.busy": "2025-02-17T01:30:28.342237Z",
     "iopub.status.idle": "2025-02-17T01:30:28.506775Z",
     "shell.execute_reply": "2025-02-17T01:30:28.506200Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydra.design import workflow, python\n",
    "\n",
    "# Example python task definitions\n",
    "@python.define\n",
    "def Add(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@python.define\n",
    "def Mul(a, b):\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can create a simple workflow definition using `workflow.define` to decorate a function that constructs the workflow. Nodes are added to the workflow being constructed by calling `workflow.add` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.508666Z",
     "iopub.status.busy": "2025-02-17T01:30:28.508476Z",
     "iopub.status.idle": "2025-02-17T01:30:28.513387Z",
     "shell.execute_reply": "2025-02-17T01:30:28.513010Z"
    }
   },
   "outputs": [],
   "source": [
    "@workflow.define\n",
    "def BasicWorkflow(a, b):\n",
    "    add = workflow.add(Add(a=a, b=b))\n",
    "    mul = workflow.add(Mul(a=add.out, b=b))\n",
    "    return mul.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`workflow.add` returns an \"outputs\" object corresponding to the definition added to the\n",
    "workflow. The fields of the outptus object can be referenced as inputs to downstream\n",
    "workflow nodes. Note that these output fields are just placeholders for the values that will\n",
    "be returned and can't be used in conditional statements during workflow construction\n",
    "(see [Dynamic construction](../explanation/conditional-lazy.html) on how to work around this\n",
    "limitation). The fields of the outputs to be returned by the workflow should be returned\n",
    "in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.514746Z",
     "iopub.status.busy": "2025-02-17T01:30:28.514592Z",
     "iopub.status.idle": "2025-02-17T01:30:28.520073Z",
     "shell.execute_reply": "2025-02-17T01:30:28.519668Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydra.design import shell\n",
    "from fileformats import image, video\n",
    "\n",
    "@workflow.define\n",
    "def ShellWorkflow(\n",
    "    input_video: video.Mp4,\n",
    "    watermark: image.Png,\n",
    "    watermark_dims: tuple[int, int] = (10, 10),\n",
    ") -> video.Mp4:\n",
    "\n",
    "    add_watermark = workflow.add(\n",
    "        shell.define(\n",
    "            \"ffmpeg -i <in_video> -i <watermark:image/png> \"\n",
    "            \"-filter_complex <filter> <out|out_video>\"\n",
    "        )(\n",
    "            in_video=input_video,\n",
    "            watermark=watermark,\n",
    "            filter=\"overlay={}:{}\".format(*watermark_dims),\n",
    "        )\n",
    "    )\n",
    "    output_video = workflow.add(\n",
    "        shell.define(\n",
    "            \"HandBrakeCLI -i <in_video:video/mp4> -o <out|out_video:video/mp4> \"\n",
    "            \"--width <width:int> --height <height:int>\",\n",
    "        )(in_video=add_watermark.out_video, width=1280, height=720)\n",
    "    ).out_video\n",
    "\n",
    "    return output_video  # test implicit detection of output name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting/combining task inputs\n",
    "\n",
    "Sometimes, you might want to perform the same task over a set of input values/files, and then collect the results into a list to perform further processing. This can be achieved by using the `split` and `combine` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.521433Z",
     "iopub.status.busy": "2025-02-17T01:30:28.521278Z",
     "iopub.status.idle": "2025-02-17T01:30:28.527281Z",
     "shell.execute_reply": "2025-02-17T01:30:28.526890Z"
    }
   },
   "outputs": [],
   "source": [
    "@python.define\n",
    "def Sum(x: list[float]) -> float:\n",
    "    return sum(x)\n",
    "\n",
    "@workflow.define\n",
    "def SplitWorkflow(a: list[int], b: list[float]) -> list[float]:\n",
    "    # Multiply over all combinations of the elements of a and b, then combine the results\n",
    "    # for each a element into a list over each b element\n",
    "    mul = workflow.add(Mul().split(x=a, y=b).combine(\"x\"))\n",
    "    # Sume the multiplications across all all b elements for each a element\n",
    "    sum = workflow.add(Sum(x=mul.out))\n",
    "    return sum.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination step doesn't have to be done on the same step as the split, in which case the splits propagate to downstream nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.528731Z",
     "iopub.status.busy": "2025-02-17T01:30:28.528481Z",
     "iopub.status.idle": "2025-02-17T01:30:28.533282Z",
     "shell.execute_reply": "2025-02-17T01:30:28.532806Z"
    }
   },
   "outputs": [],
   "source": [
    "@workflow.define\n",
    "def SplitThenCombineWorkflow(a: list[int], b: list[float], c: float) -> list[float]:\n",
    "    mul = workflow.add(Mul().split(x=a, y=b))\n",
    "    add = workflow.add(Add(x=mul.out, y=c).combine(\"Mul.x\"))\n",
    "    sum = workflow.add(Sum(x=add.out))\n",
    "    return sum.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more advanced discussion on the intricacies of splitting and combining see [Splitting and combining](../explanation/splitting-combining.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested and conditional workflows\n",
    "\n",
    "One of the most powerful features of Pydra is the ability to use inline Python code to conditionally add/omit nodes to workflow, and alter the parameterisation of the nodes, depending on inputs to the workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.534882Z",
     "iopub.status.busy": "2025-02-17T01:30:28.534576Z",
     "iopub.status.idle": "2025-02-17T01:30:28.540738Z",
     "shell.execute_reply": "2025-02-17T01:30:28.540275Z"
    }
   },
   "outputs": [],
   "source": [
    "@workflow.define\n",
    "def ConditionalWorkflow(\n",
    "    input_video: video.Mp4,\n",
    "    watermark: image.Png,\n",
    "    watermark_dims: tuple[int, int] | None = None,\n",
    ") -> video.Mp4:\n",
    "\n",
    "    if watermark_dims is not None:\n",
    "        add_watermark = workflow.add(\n",
    "            shell.define(\n",
    "                \"ffmpeg -i <in_video> -i <watermark:image/png> \"\n",
    "                \"-filter_complex <filter> <out|out_video>\"\n",
    "            )(\n",
    "                in_video=input_video,\n",
    "                watermark=watermark,\n",
    "                filter=\"overlay={}:{}\".format(*watermark_dims),\n",
    "            )\n",
    "        )\n",
    "        handbrake_input = add_watermark.out_video\n",
    "    else:\n",
    "        handbrake_input = input_video\n",
    "\n",
    "    output_video = workflow.add(\n",
    "        shell.define(\n",
    "            \"HandBrakeCLI -i <in_video:video/mp4> -o <out|out_video:video/mp4> \"\n",
    "            \"--width <width:int> --height <height:int>\",\n",
    "        )(in_video=handbrake_input, width=1280, height=720)\n",
    "    ).out_video\n",
    "\n",
    "    return output_video  # test implicit detection of output name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that outputs of upstream nodes cannot be used in conditional statements, since these are just placeholders at the time the workflow is being constructed. However, you can get around\n",
    "this limitation by placing the conditional logic within a nested workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.542351Z",
     "iopub.status.busy": "2025-02-17T01:30:28.542000Z",
     "iopub.status.idle": "2025-02-17T01:30:28.548177Z",
     "shell.execute_reply": "2025-02-17T01:30:28.547816Z"
    }
   },
   "outputs": [],
   "source": [
    "@python.define\n",
    "def Subtract(x: float, y: float) -> float:\n",
    "    return x - y\n",
    "\n",
    "@workflow.define\n",
    "def RecursiveNestedWorkflow(a: float, depth: int) -> float:\n",
    "    add = workflow.add(Add(x=a, y=1))\n",
    "    decrement_depth = workflow.add(Subtract(x=depth, y=1))\n",
    "    if depth > 0:\n",
    "        out_node = workflow.add(\n",
    "            RecursiveNestedWorkflow(a=add.out, depth=decrement_depth.out)\n",
    "        )\n",
    "    else:\n",
    "        out_node = add\n",
    "    return out_node.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detailed discussion of the construction of conditional workflows and \"lazy field\"\n",
    "placeholders see [Conditionals and lazy fields](../explanation/conditional-lazy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type-checking between nodes\n",
    "\n",
    "Pydra utilizes Python type annotations to implement strong type-checking, which is performed\n",
    "when values or upstream outputs are assigned to task definition inputs.\n",
    "\n",
    "Task input and output fields do not need to be assigned types, since they will default to `typing.Any`.\n",
    "However, if they are assigned a type and a value or output from an upstream node conflicts\n",
    "with the type, a `TypeError` will be raised at construction time.\n",
    "\n",
    "Note that the type-checking \"assumes the best\", and will pass if the upstream field is typed\n",
    "by `Any` or a super-class of the field being assigned to. For example, an input of\n",
    "`fileformats.generic.File` passed to a field expecting a `fileformats.image.Png` file type,\n",
    "because `Png` is a subtype of `File`, where as `fileformats.image.Jpeg` input would fail\n",
    "since it is clearly not the intended type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.549554Z",
     "iopub.status.busy": "2025-02-17T01:30:28.549402Z",
     "iopub.status.idle": "2025-02-17T01:30:28.622388Z",
     "shell.execute_reply": "2025-02-17T01:30:28.621960Z"
    }
   },
   "outputs": [],
   "source": [
    "from fileformats import generic\n",
    "\n",
    "Mp4Handbrake = shell.define(\n",
    "    \"HandBrakeCLI -i <in_video:video/mp4> -o <out|out_video:video/mp4> \"\n",
    "    \"--width <width:int> --height <height:int>\",\n",
    ")\n",
    "\n",
    "\n",
    "QuicktimeHandbrake = shell.define(\n",
    "    \"HandBrakeCLI -i <in_video:video/quicktime> -o <out|out_video:video/quicktime> \"\n",
    "    \"--width <width:int> --height <height:int>\",\n",
    ")\n",
    "\n",
    "@workflow.define\n",
    "def TypeErrorWorkflow(\n",
    "    input_video: video.Mp4,\n",
    "    watermark: generic.File,\n",
    "    watermark_dims: tuple[int, int] = (10, 10),\n",
    ") -> video.Mp4:\n",
    "\n",
    "    add_watermark = workflow.add(\n",
    "        shell.define(\n",
    "            \"ffmpeg -i <in_video> -i <watermark:image/png> \"\n",
    "            \"-filter_complex <filter> <out|out_video:video/mp4>\"\n",
    "        )(\n",
    "            in_video=input_video,  # This is OK because in_video is typed Any\n",
    "            watermark=watermark,  # Type is OK because generic.File is superclass of image.Png\n",
    "            filter=\"overlay={}:{}\".format(*watermark_dims),\n",
    "        ),\n",
    "        name=\"add_watermark\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        handbrake = workflow.add(\n",
    "            QuicktimeHandbrake(in_video=add_watermark.out_video, width=1280, height=720),\n",
    "        )  # This will raise a TypeError because the input video is an Mp4\n",
    "    except TypeError:\n",
    "        handbrake = workflow.add(\n",
    "            Mp4Handbrake(in_video=add_watermark.out_video, width=1280, height=720),\n",
    "        )  # The type of the input video is now correct\n",
    "\n",
    "    return handbrake.output_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detailed discussion on Pydra's type-checking see [Type Checking](../explanation/typing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the workflow object\n",
    "\n",
    "If you need to access the workflow object being constructed from inside the constructor function you can use `workflow.this()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.624078Z",
     "iopub.status.busy": "2025-02-17T01:30:28.623914Z",
     "iopub.status.idle": "2025-02-17T01:30:28.631573Z",
     "shell.execute_reply": "2025-02-17T01:30:28.631214Z"
    }
   },
   "outputs": [],
   "source": [
    "@python.define(outputs=[\"divided\"])\n",
    "def Divide(x, y):\n",
    "    return x / y\n",
    "\n",
    "\n",
    "@workflow.define(outputs=[\"out1\", \"out2\"])\n",
    "def DirectAccesWorkflow(a: int, b: float) -> tuple[float, float]:\n",
    "    \"\"\"A test workflow demonstration a few alternative ways to set and connect nodes\n",
    "\n",
    "    Args:\n",
    "        a: An integer input\n",
    "        b: A float input\n",
    "\n",
    "    Returns:\n",
    "        out1: The first output\n",
    "        out2: The second output\n",
    "    \"\"\"\n",
    "\n",
    "    wf = workflow.this()\n",
    "\n",
    "    add = wf.add(Add(x=a, y=b), name=\"addition\")\n",
    "    mul = wf.add(python.define(Mul, outputs={\"out\": float})(x=add.z, y=b))\n",
    "    divide = wf.add(Divide(x=wf[\"addition\"].lzout.z, y=mul.out), name=\"division\")\n",
    "\n",
    "    # Alter one of the inputs to a node after it has been initialised\n",
    "    wf[\"Mul\"].inputs.y *= 2\n",
    "\n",
    "    return mul.out, divide.divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly access the workflow being constructed also enables you to set the outputs of the workflow directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.633118Z",
     "iopub.status.busy": "2025-02-17T01:30:28.632815Z",
     "iopub.status.idle": "2025-02-17T01:30:28.637662Z",
     "shell.execute_reply": "2025-02-17T01:30:28.637264Z"
    }
   },
   "outputs": [],
   "source": [
    "@workflow.define(outputs={\"out1\": float, \"out2\": float})\n",
    "def SetOutputsOfWorkflow(a: int, b: float):\n",
    "    \"\"\"A test workflow demonstration a few alternative ways to set and connect nodes\n",
    "\n",
    "    Args:\n",
    "        a: An integer input\n",
    "        b: A float input\n",
    "\n",
    "    Returns:\n",
    "        out1: The first output\n",
    "        out2: The second output\n",
    "    \"\"\"\n",
    "\n",
    "    wf = workflow.this()\n",
    "\n",
    "    add = wf.add(Add(x=a, y=b), name=\"addition\")\n",
    "    mul = wf.add(python.define(Mul, outputs={\"out\": float})(x=add.z, y=b))\n",
    "    divide = wf.add(Divide(x=wf[\"addition\"].lzout.z, y=mul.out), name=\"division\")\n",
    "\n",
    "    # Alter one of the inputs to a node after it has been initialised\n",
    "    wf[\"Mul\"].inputs.y *= 2\n",
    "\n",
    "    # Set the outputs of the workflow directly\n",
    "    wf.outputs.out1 = mul.out\n",
    "    wf.outputs.out2 = divide.divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting software environments per node\n",
    "\n",
    "The [Advanced execution tutorial](./2-advanced-execution.html) showed how the software\n",
    "environment (e.g. Docker container) could be specified for shell tasks by passing the\n",
    "`environment` variable to the task execution/submission call. For shell tasks\n",
    "within workflows, the software environment used for them is specified when adding\n",
    "a new workflow node, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T01:30:28.639202Z",
     "iopub.status.busy": "2025-02-17T01:30:28.638909Z",
     "iopub.status.idle": "2025-02-17T01:31:00.889343Z",
     "shell.execute_reply": "2025-02-17T01:31:00.888703Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.25) of nipype/pydra is available. You are using 0.25.dev228+g30c954cf\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: '/home/runner/.cache/pydra/0.25.dev228+g30c954cf/run-cache/shell-3aeb59be18e3094e6135d86d674e856f/out_image.mif' -> '/home/runner/.cache/pydra/0.25.dev228+g30c954cf/run-cache/workflow-d870055d8533a1ada228b881261e27ae/out_image.mif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 75\u001b[0m\n\u001b[1;32m     71\u001b[0m nifti_file \u001b[38;5;241m=\u001b[39m Nifti1\u001b[38;5;241m.\u001b[39msample(test_dir, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     73\u001b[0m wf \u001b[38;5;241m=\u001b[39m ToyMedianThreshold(in_image\u001b[38;5;241m=\u001b[39mnifti_file)\n\u001b[0;32m---> 75\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mwf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/specs.py:243\u001b[0m, in \u001b[0;36mTaskDef.__call__\u001b[0;34m(self, cache_dir, worker, environment, rerun, cache_locations, audit_flags, messengers, messenger_args, name, hooks, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Submitter(\n\u001b[1;32m    233\u001b[0m         audit_flags\u001b[38;5;241m=\u001b[39maudit_flags,\n\u001b[1;32m    234\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m sub:\n\u001b[0;32m--> 243\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# Catch any inadvertent passing of task definition parameters to the\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# execution call\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__notes__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m WORKER_KWARG_FAIL_NOTE \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__notes__:\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/submitter.py:218\u001b[0m, in \u001b[0;36mSubmitter.__call__\u001b[0;34m(self, task_def, name, hooks)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    214\u001b[0m     e\u001b[38;5;241m.\u001b[39madd_note(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull crash report for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(task_def)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m task is here: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(task\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_error.pklz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/submitter.py:212\u001b[0m, in \u001b[0;36mSubmitter.__call__\u001b[0;34m(self, task_def, name, hooks)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39mrun_async(task, rerun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrerun)\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    214\u001b[0m     e\u001b[38;5;241m.\u001b[39madd_note(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull crash report for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(task_def)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m task is here: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(task\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_error.pklz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m     )\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/workers.py:163\u001b[0m, in \u001b[0;36mDebugWorker.run\u001b[0;34m(self, task, rerun)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    159\u001b[0m     task: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask[DefType]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m     rerun: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run a task.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrerun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/core.py:383\u001b[0m, in \u001b[0;36mTask.run\u001b[0;34m(self, rerun)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks\u001b[38;5;241m.\u001b[39mpost_run_task(\u001b[38;5;28mself\u001b[39m, result)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudit\u001b[38;5;241m.\u001b[39mfinalize_audit(result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[0;32m--> 383\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# removing the additional file with the checksum\u001b[39;00m\n\u001b[1;32m    385\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_info.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39munlink()\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/helpers.py:178\u001b[0m, in \u001b[0;36msave\u001b[0;34m(task_path, result, task, name_prefix)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    173\u001b[0m         result\u001b[38;5;241m.\u001b[39mdefinition\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_workflow(result\u001b[38;5;241m.\u001b[39mdefinition)\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     ):\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;66;03m# copy files to the workflow directory\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m         result\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;241m=\u001b[39m \u001b[43mcopyfile_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m (task_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_result.pklz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    182\u001b[0m         cp\u001b[38;5;241m.\u001b[39mdump(result, fp)\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/helpers.py:198\u001b[0m, in \u001b[0;36mcopyfile_workflow\u001b[0;34m(wf_path, outputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(outputs, field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# if the field is a path or it can contain a path _copyfile_single_value is run\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# to move all files and directories to the workflow directory\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mcopy_nested_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFileSet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCopyMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhardlink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(outputs, field\u001b[38;5;241m.\u001b[39mname, new_value)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/helpers_file.py:108\u001b[0m, in \u001b[0;36mcopy_nested_files\u001b[0;34m(value, dest_dir, supported_modes, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     cache[fileset] \u001b[38;5;241m=\u001b[39m copied\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copied\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTypeParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_to_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFileSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_fileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/utils/typing.py:955\u001b[0m, in \u001b[0;36mTypeParser.apply_to_instances\u001b[0;34m(cls, target_type, func, value, cache)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mis_instance(value, target_type):\n\u001b[0;32m--> 955\u001b[0m     modified \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mis_instance(value, ty\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    957\u001b[0m     modified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(value)(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         (\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mapply_to_instances(target_type, func, key),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (key, val) \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    963\u001b[0m     )\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/pydra/engine/helpers_file.py:99\u001b[0m, in \u001b[0;36mcopy_nested_files.<locals>.copy_fileset\u001b[0;34m(fileset)\u001b[0m\n\u001b[1;32m     96\u001b[0m cp_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     98\u001b[0m cp_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m---> 99\u001b[0m copied \u001b[38;5;241m=\u001b[39m \u001b[43mfileset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupported_modes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavoid_clashes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclashes_to_avoid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this prevents fname clashes between filesets\u001b[39;49;00m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m cache[fileset] \u001b[38;5;241m=\u001b[39m copied\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copied\n",
      "File \u001b[0;32m/usr/share/miniconda/lib/python3.12/site-packages/fileformats/core/fileset.py:1548\u001b[0m, in \u001b[0;36mFileSet.copy\u001b[0;34m(self, dest_dir, mode, collation, new_stem, prefix, stem_suffix, trim, make_dirs, overwrite, avoid_clashes, clash_template, supported_modes, extension_decomposition)\u001b[0m\n\u001b[1;32m   1546\u001b[0m         copy_dir(fspath, new_path)\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1548\u001b[0m         \u001b[43mcopy_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1549\u001b[0m     new_paths\u001b[38;5;241m.\u001b[39mappend(new_path)\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(new_paths)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: '/home/runner/.cache/pydra/0.25.dev228+g30c954cf/run-cache/shell-3aeb59be18e3094e6135d86d674e856f/out_image.mif' -> '/home/runner/.cache/pydra/0.25.dev228+g30c954cf/run-cache/workflow-d870055d8533a1ada228b881261e27ae/out_image.mif'",
      "\u001b[0mFull crash report for 'ToyMedianThreshold' task is here: /home/runner/.cache/pydra/0.25.dev228+g30c954cf/run-cache/workflow-d870055d8533a1ada228b881261e27ae/_error.pklz"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from fileformats.medimage import Nifti1\n",
    "import fileformats.medimage_mrtrix3 as mrtrix3\n",
    "from pydra.engine.environments import Docker\n",
    "from pydra.design import workflow, python\n",
    "from pydra.tasks.mrtrix3.v3_0 import MrConvert, MrThreshold\n",
    "\n",
    "MRTRIX2NUMPY_DTYPES = {\n",
    "    \"Int8\": np.dtype(\"i1\"),\n",
    "    \"UInt8\": np.dtype(\"u1\"),\n",
    "    \"Int16LE\": np.dtype(\"<i2\"),\n",
    "    \"Int16BE\": np.dtype(\">i2\"),\n",
    "    \"UInt16LE\": np.dtype(\"<u2\"),\n",
    "    \"UInt16BE\": np.dtype(\">u2\"),\n",
    "    \"Int32LE\": np.dtype(\"<i4\"),\n",
    "    \"Int32BE\": np.dtype(\">i4\"),\n",
    "    \"UInt32LE\": np.dtype(\"<u4\"),\n",
    "    \"UInt32BE\": np.dtype(\">u4\"),\n",
    "    \"Float32LE\": np.dtype(\"<f4\"),\n",
    "    \"Float32BE\": np.dtype(\">f4\"),\n",
    "    \"Float64LE\": np.dtype(\"<f8\"),\n",
    "    \"Float64BE\": np.dtype(\">f8\"),\n",
    "    \"CFloat32LE\": np.dtype(\"<c8\"),\n",
    "    \"CFloat32BE\": np.dtype(\">c8\"),\n",
    "    \"CFloat64LE\": np.dtype(\"<c16\"),\n",
    "    \"CFloat64BE\": np.dtype(\">c16\"),\n",
    "}\n",
    "\n",
    "\n",
    "@workflow.define(outputs=[\"out_image\"])\n",
    "def ToyMedianThreshold(in_image: Nifti1) -> mrtrix3.ImageFormat:\n",
    "    \"\"\"A toy example workflow that\n",
    "\n",
    "    * converts a NIfTI image to MRTrix3 image format with a separate header\n",
    "    * loads the separate data file and selects the median value\n",
    "    \"\"\"\n",
    "\n",
    "    input_conversion = workflow.add(\n",
    "        MrConvert(in_file=in_image, out_file=\"out_file.mih\"),\n",
    "        name=\"input_conversion\",\n",
    "        environment=Docker(\"mrtrix3/mrtrix3\", tag=\"latest\"),\n",
    "    )\n",
    "\n",
    "    @python.define\n",
    "    def Median(mih: mrtrix3.ImageHeader) -> float:\n",
    "        \"\"\"A bespoke function that reads the separate data file in the MRTrix3 image\n",
    "        header format (i.e. .mih) and calculates the median value.\"\"\"\n",
    "        dtype = MRTRIX2NUMPY_DTYPES[mih.metadata[\"datatype\"].strip()]\n",
    "        data = np.frombuffer(Path.read_bytes(mih.data_file), dtype=dtype)\n",
    "        return np.median(data)\n",
    "\n",
    "    median = workflow.add(Median(mih=input_conversion.out_file))\n",
    "    threshold = workflow.add(\n",
    "        MrThreshold(in_file=in_image, out_file=\"binary.mif\", abs=median.out),\n",
    "        environment=Docker(\"mrtrix3/mrtrix3\", tag=\"latest\"),\n",
    "    )\n",
    "\n",
    "    output_conversion = workflow.add(\n",
    "        MrConvert(in_file=threshold.out_file, out_file=\"out_image.mif\"),\n",
    "        name=\"output_conversion\",\n",
    "        environment=Docker(\"mrtrix3/mrtrix3\", tag=\"latest\"),\n",
    "    )\n",
    "\n",
    "    return output_conversion.out_file\n",
    "\n",
    "\n",
    "test_dir = tempfile.mkdtemp()\n",
    "\n",
    "nifti_file = Nifti1.sample(test_dir, seed=0)\n",
    "\n",
    "wf = ToyMedianThreshold(in_image=nifti_file)\n",
    "\n",
    "outputs = wf()\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Containers and Environments](../explanation/environments.rst) for more details on\n",
    "how to utilise containers and add support for other software environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
